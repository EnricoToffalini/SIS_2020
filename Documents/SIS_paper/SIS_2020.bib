
@article{calcagniMaximumEntropyProcedure2019,
  title = {A {{Maximum Entropy Procedure}} to {{Solve Likelihood Equations}}},
  author = {Calcagn{\`i}, Antonio and Finos, Livio and Alto{\'e}, Gianmarco and Pastore, Massimiliano},
  year = {2019},
  month = jun,
  volume = {21},
  pages = {596},
  issn = {1099-4300},
  doi = {10.3390/e21060596},
  abstract = {In this article, we provide initial findings regarding the problem of solving likelihood equations by means of a maximum entropy (ME) approach. Unlike standard procedures that require equating the score function of the maximum likelihood problem at zero, we propose an alternative strategy where the score is instead used as an external informative constraint to the maximization of the convex Shannon's entropy function. The problem involves the reparameterization of the score parameters as expected values of discrete probability distributions where probabilities need to be estimated. This leads to a simpler situation where parameters are searched in smaller (hyper) simplex space. We assessed our proposal by means of empirical case studies and a simulation study, the latter involving the most critical case of logistic regression under data separation. The results suggested that the maximum entropy reformulation of the score problem solves the likelihood equation problem. Similarly, when maximum likelihood estimation is difficult, as is the case of logistic regression under separation, the maximum entropy proposal achieved results (numerically) comparable to those obtained by the Firth's bias-corrected approach. Overall, these first findings reveal that a maximum entropy solution can be considered as an alternative technique to solve the likelihood equation.},
  file = {/Users/claudio/MEGA/Zotero/Calcagnì et al_2019_A Maximum Entropy Procedure to Solve Likelihood Equations.pdf},
  journal = {Entropy},
  language = {en},
  number = {6}
}

@book{cookeExpertsUncertaintyOpinion1991,
  title = {Experts in Uncertainty: Opinion and Subjective Probability in Science},
  author = {Cooke, Roger and others},
  year = {1991},
  publisher = {{Oxford University Press on Demand}},
  address = {{Oxford, UK}}
}

@article{ioannidisWhyMostPublished2005,
  title = {Why {{Most Published Research Findings Are False}}},
  author = {Ioannidis, John P. A.},
  year = {2005},
  volume = {2},
  pages = {e124},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0020124},
  abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
  file = {/Users/claudio/MEGA/Zotero/Ioannidis_2005_Why Most Published Research Findings Are False.pdf},
  journal = {PLOS Medicine},
  keywords = {Clinical research design,Finance,Genetic epidemiology,Genetics of disease,Meta-analysis,Randomized controlled trials,Research design,Schizophrenia},
  language = {en},
  number = {8}
}

@article{lemoineMovingNoninformativePriors2019,
  title = {Moving beyond Noninformative Priors: Why and How to Choose Weakly Informative Priors in {{Bayesian}} Analyses},
  shorttitle = {Moving beyond Noninformative Priors},
  author = {Lemoine, Nathan P.},
  year = {2019},
  month = jul,
  volume = {128},
  pages = {912--928},
  issn = {0030-1299, 1600-0706},
  doi = {10.1111/oik.05985},
  abstract = {Throughout the last two decades, Bayesian statistical methods have proliferated throughout ecology and evolution. Numerous previous references established both philosophical and computational guidelines for implementing Bayesian methods. However, protocols for incorporating prior information, the defining characteristic of Bayesian philosophy, are nearly nonexistent in the ecological literature. Here, I hope to encourage the use of weakly informative priors in ecology and evolution by providing a `consumer's guide' to weakly informative priors. The first section outlines three reasons why ecologists should abandon noninformative priors: 1) common flat priors are not always noninformative, 2) noninformative priors provide the same result as simpler frequentist methods, and 3) noninformative priors suffer from the same high type I and type M error rates as frequentist methods. The second section provides a guide for implementing informative priors, wherein I detail convenient `reference' prior distributions for common statistical models (i.e. regression, ANOVA, hierarchical models). I then use simulations to visually demonstrate how informative priors influence posterior parameter estimates. With the guidelines provided here, I hope to encourage the use of weakly informative priors for Bayesian analyses in ecology. Ecologists can and should debate the appropriate form of prior information, but should consider weakly informative priors as the new `default' prior for any Bayesian model.},
  file = {/Users/claudio/MEGA/Zotero/Lemoine_2019_Moving beyond noninformative priors.pdf},
  journal = {Oikos},
  language = {en},
  number = {7}
}

@article{mcneishUsingBayesianMethods2016a,
  title = {On {{Using Bayesian Methods}} to {{Address Small Sample Problems}}},
  author = {McNeish, Daniel},
  year = {2016},
  month = sep,
  volume = {23},
  pages = {750--773},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2016.1186549},
  abstract = {As Bayesian methods continue to grow in accessibility and popularity, more empirical studies are turning to Bayesian methods to model small sample data. Bayesian methods do not rely on asympotics, a property that can be a hindrance when employing frequentist methods in small sample contexts. Although Bayesian methods are better equipped to model data with small sample sizes, estimates are highly sensitive to the specification of the prior distribution. If this aspect is not heeded, Bayesian estimates can actually be worse than frequentist methods, especially if frequentist small sample corrections are utilized. We show with illustrative simulations and applied examples that relying on software defaults or diffuse priors with small samples can yield more biased estimates than frequentist methods. We discuss conditions that need to be met if researchers want to responsibly harness the advantages that Bayesian methods offer for small sample problems as well as leading small sample frequentist methods.},
  file = {/Users/claudio/MEGA/Zotero/McNeish_2016_On Using Bayesian Methods to Address Small Sample Problems2.pdf},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  language = {en},
  number = {5}
}

@article{merkleBlavaanBayesianStructural2018,
  title = {{\textbf{Blavaan}} : {{Bayesian Structural Equation Models}} via {{Parameter Expansion}}},
  shorttitle = {{\textbf{Blavaan}}},
  author = {Merkle, Edgar C. and Rosseel, Yves},
  year = {2018},
  volume = {85},
  issn = {1548-7660},
  doi = {10.18637/jss.v085.i04},
  abstract = {This article describes blavaan, an R package for estimating Bayesian structural equation models (SEMs) via JAGS and for summarizing the results. It also describes a novel parameter expansion approach for estimating specific types of models with residual covariances, which facilitates estimation of these models in JAGS. The methodology and software are intended to provide users with a general means of estimating Bayesian SEMs, both classical and novel, in a straightforward fashion. Users can estimate Bayesian versions of classical SEMs with lavaan syntax, they can obtain state-of-the-art Bayesian fit measures associated with the models, and they can export JAGS code to modify the SEMs as desired. These features and more are illustrated by example, and the parameter expansion approach is explained in detail.},
  file = {/Users/claudio/MEGA/Zotero/Merkle_Rosseel_2018_bblavaan-b.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {4}
}

@article{morrisUsingSimulationStudies2019,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  year = {2019},
  month = may,
  volume = {38},
  pages = {2074--2102},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.8086},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudorandom sampling. A key strength of simulation studies is the ability to understand the behaviour of statistical methods because some `truth' (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analysed and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting and presentation. In particular, this tutorial provides: a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods and performance measures (`ADEMP'); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine that included at least one simulation study and identify areas for improvement.},
  archivePrefix = {arXiv},
  eprint = {1712.03198},
  eprinttype = {arxiv},
  file = {/Users/claudio/MEGA/Zotero/Morris et al_2019_Using simulation studies to evaluate statistical methods.pdf},
  journal = {Statistics in Medicine},
  keywords = {Statistics - Methodology},
  language = {en},
  number = {11}
}

@misc{oakleySHELFSheffieldElicitation2016,
  title = {{{SHELF}}: The {{Sheffield Elicitation Framework}}},
  author = {Oakley, J. E. and O'Hagan, A},
  year = {2016},
  address = {{Sheffield, UK}},
  howpublished = {School of Mathematics and Statistics, University of Sheffield}
}

@article{ohaganExpertKnowledgeElicitation2019,
  title = {Expert {{Knowledge Elicitation}}: {{Subjective}} but {{Scientific}}},
  shorttitle = {Expert {{Knowledge Elicitation}}},
  author = {O'Hagan, Anthony},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {69--81},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2018.1518265},
  abstract = {Expert opinion and judgment enter into the practice of statistical inference and decision-making in numerous ways. Indeed, there is essentially no aspect of scientific investigation in which judgment is not required. Judgment is necessarily subjective, but should be made as carefully, as objectively, and as scientifically as possible.},
  file = {/Users/claudio/MEGA/Zotero/O’Hagan_2019_Expert Knowledge Elicitation.pdf},
  journal = {The American Statistician},
  keywords = {Letto},
  language = {en},
  number = {sup1}
}

@book{ohaganUncertainJudgementsEliciting2006,
  title = {Uncertain Judgements: Eliciting Experts' Probabilities},
  shorttitle = {Uncertain Judgements},
  editor = {O'Hagan, Anthony},
  year = {2006},
  publisher = {{John Wiley \& Sons}},
  address = {{London ; Hoboken, NJ}},
  file = {/Users/claudio/MEGA/Zotero/O'Hagan_2006_Uncertain judgements.pdf},
  isbn = {978-0-470-02999-2},
  keywords = {Bayes,Classic Model Cooke,Decision Theory,Delphi,Expert Elicitation,Letto,Prior,SHELF},
  language = {en},
  lccn = {QA273 .U424 2006},
  series = {Statistics in Practice}
}

@article{opensciencecollaborationEstimatingReproducibilityPsychological2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  year = {2015},
  month = aug,
  volume = {349},
  pages = {aac4716-aac4716},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aac4716},
  file = {/Users/claudio/MEGA/Zotero/Open Science Collaboration_2015_Estimating the reproducibility of psychological science.pdf},
  journal = {Science},
  language = {en},
  number = {6251}
}

@article{rosseelLavaanPackageStructural2012,
  title = {{\textbf{Lavaan}} : {{An}} {{{\emph{R}}}} {{Package}} for {{Structural Equation Modeling}}},
  shorttitle = {{\textbf{Lavaan}}},
  author = {Rosseel, Yves},
  year = {2012},
  volume = {48},
  issn = {1548-7660},
  doi = {10.18637/jss.v048.i02},
  abstract = {Structural equation modeling (SEM) is a vast field and widely used by many applied researchers in the social and behavioral sciences. Over the years, many software packages for structural equation modeling have been developed, both free and commercial. However, perhaps the best state-of-the-art software packages in this field are still closedsource and/or commercial. The R package lavaan has been developed to provide applied researchers, teachers, and statisticians, a free, fully open-source, but commercial-quality package for latent variable modeling. This paper explains the aims behind the development of the package, gives an overview of its most important features, and provides some examples to illustrate how lavaan works in practice.},
  file = {/Users/claudio/MEGA/Zotero/Rosseel_2012_blavaan-b.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {2}
}

@article{roweDelphiTechniqueForecasting1999,
  title = {The {{Delphi}} Technique as a Forecasting Tool: Issues and Analysis},
  author = {Rowe, Gene and Wright, George},
  year = {1999},
  volume = {15},
  pages = {353--375},
  publisher = {{Elsevier}},
  journal = {International journal of forecasting},
  number = {4}
}

@article{sellaPersonalityTraitsSleep2020,
  title = {Personality Traits and Sleep Quality: {{The}} Role of Sleep-Related Beliefs},
  shorttitle = {Personality Traits and Sleep Quality},
  author = {Sella, Enrico and Carbone, Elena and Toffalini, Enrico and Borella, Erika},
  year = {2020},
  month = apr,
  volume = {156},
  pages = {109770},
  issn = {01918869},
  doi = {10.1016/j.paid.2019.109770},
  abstract = {This study investigated the relationship between personality (particularly emotional stability [ES] and conscientiousness [C]), subjective sleep-related factors (dysfunctional beliefs and attitudes about sleep, and metacognitive beliefs about sleeping difficulties), and self-reported and objective sleep quality. A sample of 122 healthy participants (age range: 18\textendash{}74 years) completed the Big Five-60, the Dysfunctional Beliefs and Attitudes about Sleep questionnaire (DBAS), and the Metacognitions Questionnaire-Insomnia (MCQ-I). Self-reported and objective sleep quality were measured with the Pittsburgh Sleep Quality Index (PSQI) and actigraphic recording, respectively. The results of the mediation model showed that the subjective sleep-related factors predicted a worse self-reported sleep quality, while no direct association emerged for ES and C. One subjective sleep-related factor (metacognitive beliefs about sleeping difficulties) mediated the effect of ES on self-reported sleep quality. Objective sleep quality was only associated with C, and not with any subjective sleep-related factors. These findings suggest a differential influence of personality on sleep quality: C appears to be a personality trait ``protecting'' objective sleep quality, while stronger metacognitive beliefs about sleeping difficulties have a crucial role in explaining the link between lower ES and more self-reported sleeping difficulties.},
  file = {/Users/claudio/MEGA/Zotero/Sella et al_2020_Personality traits and sleep quality.pdf},
  journal = {Personality and Individual Differences},
  language = {en}
}

@article{smidBayesianFrequentistEstimation2020,
  title = {Bayesian {{Versus Frequentist Estimation}} for {{Structural Equation Models}} in {{Small Sample Contexts}}: {{A Systematic Review}}},
  shorttitle = {Bayesian {{Versus Frequentist Estimation}} for {{Structural Equation Models}} in {{Small Sample Contexts}}},
  author = {Smid, Sanne C. and McNeish, Daniel and Mio{\v c}evi{\'c}, Milica and {van de Schoot}, Rens},
  year = {2020},
  month = jan,
  volume = {27},
  pages = {131--161},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2019.1577140},
  abstract = {In small sample contexts, Bayesian estimation is often suggested as a viable alternative to frequentist estimation, such as maximum likelihood estimation. Our systematic literature review is the first study aggregating information from numerous simulation studies to present an overview of the performance of Bayesian and frequentist estimation for structural equation models with small sample sizes. We conclude that with small samples, the use of Bayesian estimation with diffuse default priors can result in severely biased estimates \textendash{} the levels of bias are often even higher than when frequentist methods are used. This bias can only be decreased by incorporating prior information. We therefore recommend against naively using Bayesian estimation when samples are small, and encourage researchers to make well-considered decisions about all priors. For this purpose, we provide recommendations on how to construct thoughtful priors.},
  file = {/Users/claudio/MEGA/Zotero/Smid et al_2020_Bayesian Versus Frequentist Estimation for Structural Equation Models in Small.pdf},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  keywords = {Letto Parzialmente},
  language = {en},
  number = {1}
}

@article{stefanPracticalChallengesMethodological,
  title = {Practical {{Challenges}} and {{Methodological Flexibility}} in {{Prior Elicitation}}},
  author = {Stefan, Angelika and Evans, Nathan J. and Wagenmakers, Eric-Jan},
  doi = {10.31234/osf.io/d42xb},
  abstract = {The Bayesian statistical framework requires the specification of prior distributions, which reflect pre-data knowledge about the relative plausibility of different parameter values. As prior distributions influence the results of Bayesian analyses, it is important to specify them with care. Prior elicitation has frequently been proposed as a principled method for deriving prior distributions based on expert knowledge. Although prior elicitation provides a theoretically satisfactory method of specifying prior distributions, there are several implicit decisions that researchers need to make at different stages of the elicitation process, each of them constituting important researcher degrees of freedom. Here, we discuss some of these decisions and group them into three categories: decisions about (1) the setup of the prior elicitation; (2) the core elicitation process; and (3) combination of elicited prior distributions from different experts. Importantly, different decision paths could result in greatly varying priors elicited from the same experts. Hence, researchers who wish to perform prior elicitation are advised to carefully consider each of the practical decisions before, during, and after the elicitation process. By explicitly outlining the consequences of these practical decisions, we hope to raise awareness for methodological flexibility in prior elicitation and provide researchers with a more structured approach to navigate the decision paths in prior elicitation. Making the decisions explicit also provides the foundation for further research that can identify evidence-based best practices that may eventually reduce the methodologically flexibility in prior elicitation.},
  file = {/Users/claudio/MEGA/Zotero/Stefan et al_Practical Challenges and Methodological Flexibility in Prior Elicitation.pdf},
  keywords = {To read},
  language = {en}
}

@article{wolfSampleSizeRequirements2013,
  title = {Sample {{Size Requirements}} for {{Structural Equation Models}}: {{An Evaluation}} of {{Power}}, {{Bias}}, and {{Solution Propriety}}},
  shorttitle = {Sample {{Size Requirements}} for {{Structural Equation Models}}},
  author = {Wolf, Erika J. and Harrington, Kelly M. and Clark, Shaunna L. and Miller, Mark W.},
  year = {2013},
  month = dec,
  volume = {73},
  pages = {913--934},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/0013164413495237},
  abstract = {Determining sample size requirements for structural equation modeling (SEM) is a challenge often faced by investigators, peer reviewers, and grant writers. Recent years have seen a large increase in SEMs in the behavioral science literature, but consideration of sample size requirements for applied SEMs often relies on outdated rules-of-thumb. This study used Monte Carlo data simulation techniques to evaluate sample size requirements for common applied SEMs. Across a series of simulations, we systematically varied key model properties, including number of indicators and factors, magnitude of factor loadings and path coefficients, and amount of missing data. We investigated how changes in these parameters affected sample size requirements with respect to statistical power, bias in the parameter estimates, and overall solution propriety. Results revealed a range of sample size requirements (i.e., from 30 to 460 cases), meaningful patterns of association between parameters and sample size, and highlight the limitations of commonly cited rules-of-thumb. The broad ``lessons learned'' for determining SEM sample size requirements are discussed.},
  file = {/Users/claudio/MEGA/Zotero/Wolf et al_2013_Sample Size Requirements for Structural Equation Models.pdf},
  journal = {Educational and Psychological Measurement},
  language = {en},
  number = {6}
}


